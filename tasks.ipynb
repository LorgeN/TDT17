{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT17: Key concept (FCNNs): Regularization: Heuristics: Early stopping, Data augmentation, Noise\n",
    "\n",
    "This notebook contains a Given-Find task for the key concept of regularization in deep learning. The task revolves around calculating updated bounding boxes for augmented images. Computer vision data augmentation is not yet very well supported in a lot of libraries, and was only very recently [added to PyTorch](https://pytorch.org/blog/extending-torchvisions-transforms-to-object-detection-segmentation-and-video-tasks/) in the transforms V2 API. The task is therefore actually something you may see yourself having to implement, which makes it very useful.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook requires the following Python packages:\n",
    " - requests (optional, for downloading the image)\n",
    " - matplotlib\n",
    "\n",
    "*nix commands for setting up environment and installing packages;\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install requests numpy matplotlib\n",
    "```\n",
    "\n",
    "## Task description\n",
    "\n",
    "This task assumes familiarity with the topics at hand and does not go into depth about the theory behind them. We are going to be using the below image of a parking lot, with the bounding boxes of the cars in the image, and calculating the updated bounding boxes for the augmented images. The image is augmented using a few different transforms. The code to apply the transform to the image is provided, and the task is to calculate the updated bounding boxes for the augmented images.\n",
    "\n",
    "![Parking lot with some cars](parking_lot.png)\n",
    "\n",
    "*If you do not see this image run the code below to download it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "img_data = requests.get(\"https://raw.githubusercontent.com/LorgeN/TDT17/master/parking_lot.png\").content\n",
    "with open('parking_lot.png', 'wb') as handler:\n",
    "    handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods below allow us to visualise the bounding boxes on the image, and may be useful later to verify your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class BB:\n",
    "    x: int  # x coordinate of the top left corner pixel\n",
    "    y: int  # y coordinate of the top left corner pixel\n",
    "    w: int  # width of the bounding box (in pixels)\n",
    "    h: int  # height of the bounding box (in pixels)\n",
    "\n",
    "    def __init__(self, x: int, y: int, w: int, h: int):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def with_x(self, x: int):\n",
    "        return BB(x, self.y, self.w, self.h)\n",
    "\n",
    "    def with_y(self, y: int):\n",
    "        return BB(self.x, y, self.w, self.h)\n",
    "\n",
    "    def with_xy(self, x: int, y: int):\n",
    "        return BB(x, y, self.w, self.h)\n",
    "\n",
    "    def with_wh(self, w: int, h: int):\n",
    "        return BB(self.x, self.y, w, h)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"BB(x={self.x}, y={self.y}, w={self.w}, h={self.h})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "def draw_boxes(boxes: List[BB], im: Image):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(im)\n",
    "\n",
    "    for box in boxes:\n",
    "        rect = patches.Rectangle(\n",
    "            (box.x, box.y), box.w, box.h, linewidth=1, edgecolor=\"r\", facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define the bounding boxes for the default image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = Image.open(\"parking_lot.png\")\n",
    "DEFAULT_BOUNDING_BOXES = [\n",
    "    BB(100, 220, 60, 75),\n",
    "    BB(180, 270, 50, 85),\n",
    "    BB(270, 190, 40, 85),\n",
    "    BB(395, 280, 40, 90),\n",
    "    BB(440, 195, 40, 85),\n",
    "    BB(480, 280, 40, 85),\n",
    "]\n",
    "\n",
    "draw_boxes(DEFAULT_BOUNDING_BOXES, IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Resized image\n",
    "\n",
    "The code below resizes the image. This is a very useful transform since we in many cases may not have a uniform image size in our data, and some other transforms change the image size, so applying this transform as the last in your \"chain\" is a good way to ensure uniform data. The task is to calculate the updated bounding boxes in the skeleton code.\n",
    "\n",
    "We are essentially \"multiplying\" the image by some factors in the x and y direction, and the bounding boxes should be updated accordingly. These factors are equal to\n",
    "\n",
    "$$S_x = \\frac{W_{new}}{W_{old}}$$\n",
    "\n",
    "$$S_y = \\frac{H_{new}}{H_{old}}$$\n",
    "\n",
    "where $W$ and $H$ are the width and height of the image, respectively.\n",
    "\n",
    "With these factors we can calculate the updated bounding boxes as\n",
    "\n",
    "$$x_{new} = x_{old} \\cdot S_x$$\n",
    "\n",
    "$$y_{new} = y_{old} \\cdot S_y$$\n",
    "\n",
    "$$w_{new} = w_{old} \\cdot S_x$$\n",
    "\n",
    "$$h_{new} = h_{old} \\cdot S_y$$\n",
    "\n",
    "where $x$ and $y$ are the coordinates of the top left corner of the bounding box, and $w$ and $h$ are the width and height of the bounding box, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dimensions = IMAGE.size\n",
    "resized_image = IMAGE.resize((600, 400))\n",
    "\n",
    "resized_bounding_boxes = [\n",
    "    BB(\n",
    "        box.x, # TODO: Update x coordinate\n",
    "        box.y, # TODO: Update y coordinate\n",
    "        box.w, # TODO: Update w\n",
    "        box.h, # TODO: Update h\n",
    "    )\n",
    "    for box in DEFAULT_BOUNDING_BOXES\n",
    "]\n",
    "\n",
    "draw_boxes(resized_bounding_boxes, resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Flipped image\n",
    "\n",
    "The code below flips the image horizontally. The task is to implement the logic for calculating the updated bounding boxes for the flipped image in the skeleton code below. \n",
    "\n",
    "The math for this transform is relatively straightforward. Our width and heigh remains the same, and since we are flipping horizontally, we only need to update our x coordinates. We have to remember that our reference point for the coordinate is the top left corner of the box. This means that the new x coordinate is equal to $$x_{new} = \\text{image width} - \\text{box width} - x_{old}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_image = IMAGE.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "flipped_bounding_boxes = [\n",
    "    box.with_x(box.x) for box in DEFAULT_BOUNDING_BOXES  # TODO: Update x coordinate\n",
    "]\n",
    "\n",
    "draw_boxes(flipped_bounding_boxes, flipped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Cropped image\n",
    "\n",
    "The code below crops the image. The task is to implement the logic for calculating the updated bounding boxes for the cropped image in the skeleton code below.\n",
    "\n",
    "This does not involve scaling, making it a question of translating the bounding boxes. Since we are cropping the image, we need to make sure that the bounding boxes are still within the image. This means that we need to check if the bounding box is outside the image, and if it is, we should either remove it or update the size.\n",
    "\n",
    "First we should translate the boxes by the top left crop, which in this case is both 60 pixels. We do this simply by subtracting 60 from the x and y coordinates:\n",
    "\n",
    "$$x_{new} = x_{old} - 60$$\n",
    "\n",
    "$$y_{new} = y_{old} - 60$$\n",
    "\n",
    "Then we need to check if the bounding box is outside the image. This has to be done as several steps:\n",
    "\n",
    "1. If $x < 0$ -> $x = 0$ and update width by $w = w + x$ since we are removing $x$ pixels from the left side of the image\n",
    "2. If $y < 0$ -> $y = 0$ and update height by $h = h + y$ since we are removing $y$ pixels from the top of the image\n",
    "3. If $x + w > W$ -> $w = W - x$ since we are removing $x$ pixels from the right side of the image\n",
    "4. If $y + h > H$ -> $h = H - y$ since we are removing $y$ pixels from the bottom of the image\n",
    "\n",
    "where $W$ and $H$ are the width and height of the image, respectively.\n",
    "\n",
    "Now, if the bounding box is outside the image, we should remove it. We can check this by checking if the width or height is less than or equal to 0. If it is, we should remove the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = IMAGE.crop((60, 60, 440, 340))\n",
    "\n",
    "cropped_bounding_boxes = []\n",
    "\n",
    "for box in DEFAULT_BOUNDING_BOXES:\n",
    "    updated = box  # TODO: Update box\n",
    "\n",
    "    cropped_bounding_boxes.append(updated)\n",
    "\n",
    "draw_boxes(cropped_bounding_boxes, cropped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Rotate image\n",
    "\n",
    "The code below rotates the image 3 degrees around the center point. The task is to implement the logic for calculating the updated bounding boxes for the rotated image in the skeleton code below.\n",
    "\n",
    "The math for this transform is a bit more involved. We should consider the top left and bottom right corner of the bounding box, and rotate it around the center point of the image. We can calculate the center point of the image as\n",
    "\n",
    "$$x_{center} = \\frac{W}{2}$$\n",
    "\n",
    "$$y_{center} = \\frac{H}{2}$$\n",
    "\n",
    "where $W$ and $H$ are the width and height of the image, respectively.\n",
    "\n",
    "We can then use \n",
    "\n",
    "$$x_{new} = x_{center} + (x_{old} - x_{center}) \\cdot \\cos(\\theta) - (y_{old} - y_{center}) \\cdot \\sin(\\theta)$$\n",
    "\n",
    "$$y_{new} = y_{center} + (x_{old} - x_{center}) \\cdot \\sin(\\theta) + (y_{old} - y_{center}) \\cdot \\cos(\\theta)$$\n",
    "\n",
    "to rotate counter-clockwise where $\\theta$ is the angle of rotation, which in this case is 3 degrees. Since this rotation is counter-clockwise we will need to use -3 degrees instead.\n",
    "\n",
    "Since we can not represent an angled bounding box, we need to calculate the new width and height of the bounding box. We can do this by calculating the distance between the corners of the bounding box.\n",
    "\n",
    "We can find the bottom right corner using\n",
    "\n",
    "$$x_{bottom right} = x_{old} + w_{old}$$\n",
    "\n",
    "$$y_{bottom right} = y_{old} + h_{old}$$\n",
    "\n",
    "**Hint: Remember that python math uses radians! Use `math.radians` to convert from degrees to radians**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "rotated_image = IMAGE.rotate(3)\n",
    "\n",
    "rotated_bounding_boxes = []\n",
    "\n",
    "\n",
    "for box in DEFAULT_BOUNDING_BOXES:\n",
    "    updated = box # TODO: Update box coordinates\n",
    "\n",
    "    rotated_bounding_boxes.append(updated)\n",
    "\n",
    "\n",
    "draw_boxes(rotated_bounding_boxes, rotated_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
